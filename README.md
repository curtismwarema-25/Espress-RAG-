# Espresso(RAG)

## ğŸš€ Retrieval-Augmented Generation (RAG) with GPT4All

Espresso(RAG) is a **local Retrieval-Augmented Generation (RAG) system** leveraging **GPT4All** and **FAISS** for efficient document retrieval and question answering. This project ensures privacy and cost efficiency by running **fully offline** with local embeddings and models.

---

## ğŸ›  Features
- **ğŸ’¾ Local Model** â€“ Uses GPT4All instead of OpenAI API to avoid rate limits and enhance privacy.
- **ğŸ” Document Retrieval** â€“ Indexes and retrieves documents using FAISS.
- **ğŸ“„ Text Chunking** â€“ Splits documents into smaller chunks for efficient retrieval.
- **ğŸ§  Local Embeddings** â€“ Utilizes Hugging Face models for vector embeddings.

---

## ğŸ“¥ Installation

### 1ï¸âƒ£ **Clone the Repository**
```sh
git clone https://github.com/yourusername/Espresso-RAG.git
cd Espresso-RAG
```

### 2ï¸âƒ£ **Set Up a Virtual Environment**
```sh
python -m venv venv
source venv/bin/activate  # On Windows, use 'venv\Scripts\activate'
```

### 3ï¸âƒ£ **Install Dependencies**
```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ **Download GPT4All Model**
Ensure you have a GPT4All-compatible model downloaded and placed in:
```sh
C:/Users/curtis mwarema/AppData/Local/nomic.ai/GPT4All/
```

Set the path in **.env**:
```env
GPT4ALL_MODEL_PATH=C:/Users/curtis mwarema/AppData/Local/nomic.ai/GPT4All/YourModel.gguf
```

---

## ğŸš€ Usage

### **Run the RAG System**
```sh
python rag_demo.py
```

### **Ask a Question**
Modify `rag_demo.py` to input custom questions:
```python
question = "What is Espresso(RAG)?"
```
---

## ğŸ“œ Project Structure
```
Espresso-RAG/
â”‚â”€â”€ documents.txt        # Text file with source documents
â”‚â”€â”€ rag_demo.py          # Main script for running RAG
â”‚â”€â”€ .env                 # Stores environment variables (API keys, model paths)
â”‚â”€â”€ requirements.txt     # Project dependencies
â”‚â”€â”€ README.md            # Project documentation (this file)
â”‚â”€â”€ venv/                # Virtual environment
```
---

## ğŸ›  Technologies Used
- **LangChain** â€“ Orchestrates retrieval and response generation
- **GPT4All** â€“ Local LLM for answering questions
- **FAISS** â€“ Efficient similarity search and document retrieval
- **Hugging Face Embeddings** â€“ Converts text into vector representations
- **Python dotenv** â€“ Loads environment variables

---

## ğŸ¯ Future Improvements
- âœ… Support for larger document collections
- âœ… Improved UI for interactive querying
- âœ… Fine-tuned local models for better responses

---

## ğŸ“¬ Contact
For inquiries, reach out via:
ğŸ“§ Email: curtismwarema01@gmail.com

---

### ğŸ”¥ Ready for the Interview! ğŸ¤

